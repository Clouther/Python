# Determine importance of words in collection of documents using TF-IDF

# important libraries that will be used 
import requests
import math
import nltk
from nltk.corpus import stopwords
from textblob import TextBlob as tb
from string import punctuation

nltk.download("stopwords")

# Getting doc1
doc1 = requests.get('https://raw.githubusercontent.com/MicrosoftLearning/AI-Introduction/master/files/Moon.txt')
doc1text = doc1.text
txt1 = ''.join(c for c in doc1text if not c.isdigit())
txt1 = ''.join(c for c in txt1 if c not in punctuation).lower()
txt1 = ' '.join([word for word in txt1.split() if word not in (stopwords.words('english'))])

# Getting doc2
doc2 = requests.get('https://raw.githubusercontent.com/MicrosoftLearning/AI-Introduction/master/files/Gettysburg.txt')
doc2text = doc2.text
txt2 = ''.join(c for c in doc2text if not c.isdigit())
txt2 = ''.join(c for c in txt2 if c not in punctuation).lower()
txt2 = ' '.join([word for word in txt2.split() if word not in (stopwords.words('english'))])

# Getting doc3
doc3 = requests.get('https://raw.githubusercontent.com/MicrosoftLearning/AI-Introduction/master/files/Cognitive.txt')
doc3text = doc3.text
txt3 = ''.join(c for c in doc3text if not c.isdigit())
txt3 = ''.join(c for c in txt3 if c not in punctuation).lower()
txt3 = ' '.join([word for word in txt3.split() if word not in (stopwords.words('english'))])

def tf(word, doc):
    lenOfDoc = len(doc.words)
    if lenOfDoc < 1: return 0
    else: return doc.words.count(word) / lenOfDoc

def contains(word, docs):
    return sum(1 for doc in docs if word in doc.words)

def idf(word, docs):
    docsCount = contains(word, docs)
    if docsCount < 1 : return 0
    else: return math.log(len(docs) / docsCount)

def tfidf(word, doc, docs):
    return tf(word,doc) * idf(word, docs)

# Create a collection of documents as textblobs
doc1 = tb(txt)
doc2 = tb(txt2)
doc3 = tb(txt3)
docs = [doc1, doc2, doc3]

# Use TF-IDF to get the three most important words from each document
print('-----------------------------------------------------------')
for i, doc in enumerate(docs):
    print("Top words in document {}".format(i + 1))
    scores = {word: tfidf(word, doc, docs) for word in doc.words}
    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    for word, score in sorted_words[:5]:
        print("\tWord: {}, TF-IDF: {}".format(word, round(score, 5)))



