# Examples of different models using Scikit-Learn - prepared data ~ data that has been preprocessed and cleaned

# Linear Regression using Scikit-Learn (evaluating model)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

lin_reg = LinearRegression()          
lin_reg.fit(prepared_training_data, training_labels)    # Fit the linear regression model on the prepared data 
lin_reg_predictions = lin_reg.predict(prepared_test_data)
lin_mse = mean_squared_error(testing_labels, prepared_test_data)   # Getting the mean squared error
lin_rmse = np.sqrt(lin_mse)   # Getting the root mean squared error 

# Using a Decision Tree Regression model (same procedure for models)

from sklearn.linear_model import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor()
tree_reg.fit(prepared_training_data, training_labels)   # Fit the DecisionTree model on the prepared data
tree_reg_predictions = tree_reg.predict(prepared_test_data)
tree_mse = mean_squared_error(testing_labels, prepared_test_data)  # Getting the mean squared error
tree_rmse = np.sqrt(tree_mse)  # Getting the root mean squared error

# Using K-fold Cross-Validation to evaluate a model of our choosing

from sklearn.model selection import cross_val_score
from sklearn.externals import joblib   # Will be used to store our model

scores = cross_val_score(model, prepared_training_data, training_labels,
                         scoring = "neg_mean_squared_error", cv=10
                         )
rmse_scores = np.sqrt(-scores.mean())     # Negative because CV uses a utility function, scoring is the opposite
joblib.dump(model, "my_saved_model.pkl")  # Saving the model using the pickle format
joblib.load("my_saved_model.pkl")         # Loading the model

# Using GridSearchCV to find "best" Hyperparameters for our model

from sklearn.model_selection import GridSearchCV
 
param_grid = [                           # Creating a param_grid based on what you want the GridSearch to optimize. Features depend on model that is used.
        {'n_estimators': [3, 10, 30], 'max_features': [2,4,6,8]},
        {'boostrap': [False], 'n_estimators': [3,10], 'max_features': [2,3,4]},
        ]

forest_reg = RandomForestRegressor()

grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
                           scoring='neg_mean_squared_error',
                           return_train_score=True)

grid_search.fit(prepared_training_data, training_labels)

grid_search.best_params_  # Getting the best parameteres

# Using RandomizedSearchCV to find "best" Hyperparameters for our model (RandomForestRegressor in example)

from sklearn.model_selection import RandomizedSearchCV    

rf = RandomForestRegressor()
rf.get_params()  # Getting a list of params that we can have our RandomizedSearchCV "optimize"

# Setting up our parameters for our RandomizedSearchCV
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]

random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}


Random_search = RandomizedSearchCV(forest_reg, random_grid , n_iter=4, cv =5, 
                                   scoring='neg_mean_squared_error',
                                   random_state=23)

Random_search.fit(prepared_training_data, training_labels)

# Getting the feature importance

feature_random_importnace = Random_search.best_estimator_.feature_importances_
feature_random_importnace


